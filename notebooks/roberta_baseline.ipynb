{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Colab: False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "print(\"In Colab:\", IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !pip install transformers datasets torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import DatasetDict, load_dataset, load_from_disk\n",
    "\n",
    "import evaluate\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    get_scheduler\n",
    ")\n",
    "\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(filepath: str, seed = None, validation_split=0.1, test_split=0.1) -> DatasetDict:\n",
    "    \"\"\"Load dataset from filepath\"\"\"\n",
    "    ds = load_dataset(\"csv\", data_files=filepath)\n",
    "    ds_size = len(ds[\"train\"])\n",
    "\n",
    "    ds = ds.class_encode_column(\"topic\")\n",
    "    ds = ds.class_encode_column(\"stance\")\n",
    "    \n",
    "    # Create a function that converts the `created_at` column to a datetime object\n",
    "    def convert_to_datetime(example):\n",
    "        example[\"created_at\"] = pd.to_datetime(example[\"created_at\"])\n",
    "        return example\n",
    "\n",
    "    ds = ds.map(convert_to_datetime)\n",
    "\n",
    "    # Split dataset into train, validation, and test\n",
    "    ds = ds.shuffle(seed=seed)\n",
    "    ds_first_split = ds[\"train\"].train_test_split(test_size=test_split)\n",
    "    ds_second_split = ds_first_split[\"train\"].train_test_split(test_size=validation_split)\n",
    "    ds = DatasetDict(\n",
    "        {\n",
    "            \"train\": ds_second_split[\"train\"],\n",
    "            \"validation\": ds_second_split[\"test\"],\n",
    "            \"test\": ds_first_split[\"test\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    final_ds_size = sum([len(ds[split]) for split in ds.keys()])\n",
    "    assert ds_size == final_ds_size, \"Dataset size mismatch\"\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0a5351428777341c\n",
      "Found cached dataset csv (/Users/bguisard/.cache/huggingface/datasets/csv/default-0a5351428777341c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b14cad9c2fc4ad8a0a1fab8b06537ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/bguisard/.cache/huggingface/datasets/csv/default-0a5351428777341c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-c35ca081c99db987.arrow\n",
      "Loading cached processed dataset at /Users/bguisard/.cache/huggingface/datasets/csv/default-0a5351428777341c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ca2dd53b6260951e.arrow\n",
      "Loading cached processed dataset at /Users/bguisard/.cache/huggingface/datasets/csv/default-0a5351428777341c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-06656eb34698d481.arrow\n",
      "Loading cached processed dataset at /Users/bguisard/.cache/huggingface/datasets/csv/default-0a5351428777341c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-3e3313e9846e0349.arrow\n",
      "Loading cached processed dataset at /Users/bguisard/.cache/huggingface/datasets/csv/default-0a5351428777341c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ce6b7aceaf5b0e8c.arrow\n"
     ]
    }
   ],
   "source": [
    "path = \"UPDATE THIS PATH\"\n",
    "ds = generate_dataset(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloaders(ds: DatasetDict, tokenizer, data_collator) -> DatasetDict:\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"message\"], truncation=True)\n",
    "\n",
    "    tokenized_ds = ds.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Clean Dataset\n",
    "    tokenized_ds = tokenized_ds.remove_columns(\n",
    "        [\"message\", \"created_at\", \"id\", \"aggressiveness\", \"sentiment\", \"stance\"]\n",
    "    )\n",
    "    tokenized_ds = tokenized_ds.rename_column(\"topic\", \"labels\")\n",
    "\n",
    "    # Create dataloaders\n",
    "    dls = {}\n",
    "    for split in tokenized_ds.keys():\n",
    "        dls[split] = DataLoader(\n",
    "            tokenized_ds[split],\n",
    "            shuffle=True,\n",
    "            batch_size=8,\n",
    "            collate_fn=data_collator,\n",
    "        )\n",
    "\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ae5fc508b8492ea5df21d4b2f8ca0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761ec395f0174796aa5259d26f2f1b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70c818422074fd78594dc7b5ad8de94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = dataloaders(ds, tokenizer, data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=10, ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(dls['train'])\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dls['train']:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# I tried using the `evaluate.combine` method and the `add_batch`, but I was\n",
    "# getting an an error caused by the multiple classes.\n",
    "\n",
    "# metrics = evaluate.combine(\n",
    "#     [\n",
    "#         evaluate.load(\"accuracy\"),\n",
    "#         evaluate.load(\"f1\"),\n",
    "#         evaluate.load(\"precision\"),\n",
    "#         evaluate.load(\"recall\"),\n",
    "#         evaluate.load(\"roc_auc\", \"multiclass\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "all_preds = []\n",
    "for batch in dls['validation']:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    softmax = torch.softmax(logits, dim=-1)\n",
    "    predictions = torch.argmax(softmax, dim=-1)\n",
    "\n",
    "    labels.extend(batch[\"labels\"].tolist())\n",
    "    preds.extend(predictions.tolist())\n",
    "    all_preds.extend(softmax.tolist())\n",
    "\n",
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "roc_auc_metric = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "# Wrap all the metrics above in a dictionary\n",
    "metrics = {\n",
    "    \"f1\": f1_metric,\n",
    "    \"recall\": recall_metric,\n",
    "    \"precision\": precision_metric,\n",
    "    \"accuracy\": accuracy_metric,\n",
    "    \"roc_auc\": roc_auc_metric,\n",
    "}\n",
    "\n",
    "# Compute the metrics\n",
    "results = {}\n",
    "for metric_name, metric in metrics.items():\n",
    "    print(metric_name)\n",
    "    if metric_name == \"accuracy\":\n",
    "        r = metric.compute(predictions=preds, references=labels)\n",
    "    elif metric_name == \"roc_auc\":\n",
    "        r = metric.compute(\n",
    "            prediction_scores=all_preds, references=labels, multi_class=\"ovr\"\n",
    "        )\n",
    "    else:\n",
    "        r = metric.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "    results.update(r)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c095221bc623b78cc659b45d5b2be4c617356237c1d6b69bd7b50803e0887f8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
